{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Variable Transformation\n",
    "Notebook by Abhinav Moudgil and Neural Network Visualisation by Attila Bagoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PATH_TO_JSMVA_FOLDER=\"/Users/testuser/gsoc-2016/GSOC16/src/python/\"\n",
    "sys.path.append(os.path.expanduser(PATH_TO_JSMVA_FOLDER))\n",
    "import JsMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook'],\n",
       "  function() {\n",
       "    IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};\n",
       "    console.log(\"JupyROOT - %%cpp magic configured\");\n",
       "  }\n",
       ");\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.07/07\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile, TMVA, TCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%jsmva on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  : You are running ROOT Version: 6.07/07, Apr 1, 2016\n",
      "--- Factory                  : \n",
      "--- Factory                  : _/_/_/_/_/ _|      _|  _|      _|    _|_|   \n",
      "--- Factory                  :    _/      _|_|  _|_|  _|      _|  _|    _| \n",
      "--- Factory                  :   _/       _|  _|  _|  _|      _|  _|_|_|_| \n",
      "--- Factory                  :  _/        _|      _|    _|  _|    _|    _| \n",
      "--- Factory                  : _/         _|      _|      _|      _|    _| \n",
      "--- Factory                  : \n",
      "--- Factory                  : ___________TMVA Version 4.2.1, Feb 5, 2015\n",
      "--- Factory                  : \n"
     ]
    }
   ],
   "source": [
    "outputFile = TFile(\"TMVAOutput.root\", \"RECREATE\")\n",
    "inputFile  = TFile(\"../datasets/mydataset.root\")\n",
    "\n",
    "TMVA.Tools.Instance()\n",
    "\n",
    "factory = TMVA.Factory(\"TMVAClassification\",\n",
    "                       outputFile,\n",
    "                       \"!V:ROC:!Correlations:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\")\n",
    "   \n",
    "loader = TMVA.DataLoader(\"mydataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding variables to dataset\n",
    "loader.AddVariable(\"var0\", 'F')\n",
    "loader.AddVariable(\"var1\", 'F')\n",
    "loader.AddVariable(\"var2\", 'F')\n",
    "loader.AddVariable(\"var3 := var0-var1\", 'F')\n",
    "loader.AddVariable(\"var4 := var0*var2\", 'F')\n",
    "loader.AddVariable(\"var5 := var1+var2\", 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TMVAClassification       : Using input file: ../datasets/mydataset.root\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Signal\"\t with internal class number 0\n",
      "--- mydataset                : Add Tree MyMCSig of type Signal with 5449 events\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Background\"\t with internal class number 1\n",
      "--- mydataset                : Add Tree MyMCBkg of type Background with 5449 events\n",
      "--- mydataset                : Preparing trees for training and testing...\n"
     ]
    }
   ],
   "source": [
    "print \"--- TMVAClassification       : Using input file:\", inputFile.GetName()\n",
    "   \n",
    "# Register the training and test trees\n",
    "\n",
    "tsignal     = inputFile.Get(\"MyMCSig\")\n",
    "tbackground = inputFile.Get(\"MyMCBkg\")\n",
    "     \n",
    "signalWeight     = 1.0\n",
    "backgroundWeight = 1.0\n",
    "\n",
    "mycuts = TCut(\"\")\n",
    "mycutb = TCut(\"\")\n",
    "\n",
    "loader.AddSignalTree(tsignal, signalWeight)\n",
    "loader.AddBackgroundTree(tbackground, backgroundWeight)\n",
    "loader.fSignalWeight = signalWeight\n",
    "loader.fBackgroundWeight = backgroundWeight\n",
    "loader.fTreeS = tsignal\n",
    "loader.fTreeB = tbackground\n",
    "loader.PrepareTrainingAndTestTree(mycuts,\n",
    "                                  mycutb,\n",
    "                                  \"nTrain_Signal=3000:nTrain_Background=3000:nTest_Signal=1449:nTest_Background=1449:SplitMode=Random:NormMode=NumEvents:!V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodMLP object (\"MLP\") at 0x7fdb8e4b3400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  : Booking method: \u001b[1mMLP\u001b[0m DataSet Name: \u001b[1mmydataset\u001b[0m\n",
      "--- MLP                      : Dataset[mydataset] : Create Transformation \"N\" with events from all classes.\n",
      "--- Norm                     : Transformation, Variable selection : \n",
      "--- Norm                     : Input : variable 'var0' (index=0).   <---> Output : variable 'var0' (index=0).\n",
      "--- Norm                     : Input : variable 'var1' (index=1).   <---> Output : variable 'var1' (index=1).\n",
      "--- Norm                     : Input : variable 'var2' (index=2).   <---> Output : variable 'var2' (index=2).\n",
      "--- Norm                     : Input : variable 'var3' (index=3).   <---> Output : variable 'var3' (index=3).\n",
      "--- Norm                     : Input : variable 'var4' (index=4).   <---> Output : variable 'var4' (index=4).\n",
      "--- Norm                     : Input : variable 'var5' (index=5).   <---> Output : variable 'var5' (index=5).\n",
      "--- MLP                      : Building Network\n",
      "--- MLP                      : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(loader,\n",
    "                   TMVA.Types.kMLP,\n",
    "                   \"MLP\",\n",
    "                   \"!V:NeuronType=tanh:VarTransform=N:NCycles=150:HiddenLayers=N+5:TestRate=5:!UseRegulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  :  \n",
      "--- Factory                  : Train all methods for Classification ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Splitmode is: \"RANDOM\" the mixmode is: \"SAMEASSPLITMODE\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create training and testing trees -- looping over class \"Signal\" ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight expression for class 'Signal': \"\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create training and testing trees -- looping over class \"Background\" ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight expression for class 'Background': \"\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Number of events in input trees (after possible flattening of arrays):\n",
      "--- DataSetFactory           : Dataset[mydataset] :     Signal          -- number of events       : 5449   / sum of weights: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] :     Background      -- number of events       : 5449   / sum of weights: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] :     Signal     tree -- total number of entries: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] :     Background tree -- total number of entries: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] : Preselection: (will NOT affect number of requested training and testing events)\n",
      "--- DataSetFactory           : Dataset[mydataset] :     No preselection cuts applied on event classes\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight renormalisation mode: \"NumEvents\": renormalises all event classes \n",
      "--- DataSetFactory           : Dataset[mydataset] :  such that the effective (weighted) number of events in each class equals the respective \n",
      "--- DataSetFactory           : Dataset[mydataset] :  number of events (entries) that you demanded in PrepareTrainingAndTestTree(\"\",\"nTrain_Signal=.. )\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ... i.e. such that Sum[i=1..N_j]{w_i} = N_j, j=0,1,2...\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ... (note that N_j is the sum of TRAINING events (nTrain_j...with j=Signal,Background..\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor! )\n",
      "--- DataSetFactory           : Dataset[mydataset] : --> Rescale Signal     event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[mydataset] : --> Rescale Background event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[mydataset] : Number of training and testing events after rescaling:\n",
      "--- DataSetFactory           : Dataset[mydataset] : ---------------------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal     -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal     -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal     -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create internal training tree\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create internal testing tree\n",
      "--- DataSetInfo              : Dataset[mydataset] : Correlation matrix (Signal):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :               var0    var1    var2 var0-var1 var0*var2 var1+var2\n",
      "--- DataSetInfo              :      var0:  +1.000  -0.008  +0.011    +0.852    +0.922    +0.000\n",
      "--- DataSetInfo              :      var1:  -0.008  +1.000  +0.010    -0.531    -0.004    +0.811\n",
      "--- DataSetInfo              :      var2:  +0.011  +0.010  +1.000    +0.004    +0.335    +0.593\n",
      "--- DataSetInfo              : var0-var1:  +0.852  -0.531  +0.004    +1.000    +0.784    -0.425\n",
      "--- DataSetInfo              : var0*var2:  +0.922  -0.004  +0.335    +0.784    +1.000    +0.192\n",
      "--- DataSetInfo              : var1+var2:  +0.000  +0.811  +0.593    -0.425    +0.192    +1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              : Dataset[mydataset] : Correlation matrix (Background):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :               var0    var1    var2 var0-var1 var0*var2 var1+var2\n",
      "--- DataSetInfo              :      var0:  +1.000  -0.008  +0.008    +0.650    +0.670    -0.001\n",
      "--- DataSetInfo              :      var1:  -0.008  +1.000  +0.009    -0.766    +0.001    +0.738\n",
      "--- DataSetInfo              :      var2:  +0.008  +0.009  +1.000    -0.002    +0.696    +0.682\n",
      "--- DataSetInfo              : var0-var1:  +0.650  -0.766  -0.002    +1.000    +0.431    -0.561\n",
      "--- DataSetInfo              : var0*var2:  +0.670  +0.001  +0.696    +0.431    +1.000    +0.471\n",
      "--- DataSetInfo              : var1+var2:  -0.001  +0.738  +0.682    -0.561    +0.471    +1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[mydataset] :  \n",
      "--- Factory                  : \n",
      "--- Factory                  : current transformation string: 'I'\n",
      "--- Factory                  : Dataset[mydataset] : Create Transformation \"I\" with events from all classes.\n",
      "--- Id                       : Transformation, Variable selection : \n",
      "--- Id                       : Input : variable 'var0' (index=0).   <---> Output : variable 'var0' (index=0).\n",
      "--- Id                       : Input : variable 'var1' (index=1).   <---> Output : variable 'var1' (index=1).\n",
      "--- Id                       : Input : variable 'var2' (index=2).   <---> Output : variable 'var2' (index=2).\n",
      "--- Id                       : Input : variable 'var3' (index=3).   <---> Output : variable 'var3' (index=3).\n",
      "--- Id                       : Input : variable 'var4' (index=4).   <---> Output : variable 'var4' (index=4).\n",
      "--- Id                       : Input : variable 'var5' (index=5).   <---> Output : variable 'var5' (index=5).\n",
      "--- Id                       : Preparing the Identity transformation...\n",
      "--- TFHandler_Factory        : -----------------------------------------------------------\n",
      "--- TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "--- TFHandler_Factory        : -----------------------------------------------------------\n",
      "--- TFHandler_Factory        :     var0:     3.0588     1.6838   [   0.043380     9.9950 ]\n",
      "--- TFHandler_Factory        :     var1:     1.5648     1.4226   [ 9.9424e-05     4.9967 ]\n",
      "--- TFHandler_Factory        :     var2:     3.5262     1.2078   [ 0.00088645     4.9993 ]\n",
      "--- TFHandler_Factory        :     var3:     1.4940     2.2267   [    -4.4454     9.9615 ]\n",
      "--- TFHandler_Factory        :     var4:     10.832     7.5632   [ 0.00088366     48.220 ]\n",
      "--- TFHandler_Factory        :     var5:     5.0910     1.7735   [    0.14162     9.8702 ]\n",
      "--- TFHandler_Factory        : -----------------------------------------------------------\n",
      "--- TFHandler_Factory        : Plot event variables for Id\n",
      "--- TFHandler_Factory        : Create scatter and profile plots in target-file directory: \n",
      "--- TFHandler_Factory        : TMVAOutput.root:/mydataset/InputVariables_Id/CorrelationPlots\n",
      "--- TFHandler_Factory        :  \n",
      "--- TFHandler_Factory        : Ranking input variables (method unspecific)...\n",
      "--- IdTransformation         : Ranking result (top variable is best ranked)\n",
      "--- IdTransformation         : -----------------------------\n",
      "--- IdTransformation         : Rank : Variable  : Separation\n",
      "--- IdTransformation         : -----------------------------\n",
      "--- IdTransformation         :    1 : var3      : 2.738e-01\n",
      "--- IdTransformation         :    2 : var1      : 1.314e-01\n",
      "--- IdTransformation         :    3 : var2      : 1.190e-01\n",
      "--- IdTransformation         :    4 : var0      : 9.708e-02\n",
      "--- IdTransformation         :    5 : var5      : 5.815e-02\n",
      "--- IdTransformation         :    6 : var4      : 5.589e-02\n",
      "--- IdTransformation         : -----------------------------\n",
      "--- Factory                  : Train method: MLP for Classification\n",
      "--- Norm                     : Preparing the transformation.\n",
      "--- TFHandler_MLP            : -----------------------------------------------------------\n",
      "--- TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "--- TFHandler_MLP            : -----------------------------------------------------------\n",
      "--- TFHandler_MLP            :     var0:   -0.39399    0.33839   [    -1.0000     1.0000 ]\n",
      "--- TFHandler_MLP            :     var1:   -0.37371    0.56942   [    -1.0000     1.0000 ]\n",
      "--- TFHandler_MLP            :     var2:    0.41058    0.48327   [    -1.0000     1.0000 ]\n",
      "--- TFHandler_MLP            :     var3:   -0.17548    0.30911   [    -1.0000     1.0000 ]\n",
      "--- TFHandler_MLP            :     var4:   -0.55077    0.31370   [    -1.0000     1.0000 ]\n",
      "--- TFHandler_MLP            :     var5:   0.017481    0.36460   [    -1.0000     1.0000 ]\n",
      "--- TFHandler_MLP            : -----------------------------------------------------------\n",
      "--- MLP                      : Dataset[mydataset] : Begin training\n",
      "--- MLP                      : Training Network\n",
      "--- MLP                      : Dataset[mydataset] : End of training                                              \n",
      "--- MLP                      : Dataset[mydataset] : Elapsed time for training with 6000 events: \u001b[1;31m4.73 sec\u001b[0m         \n",
      "--- MLP                      : Dataset[mydataset] : Create MVA output for Dataset[mydataset] : classification on training sample\n",
      "--- MLP                      : Dataset[mydataset] : Evaluation of MLP on training sample (6000 events)\n",
      "--- MLP                      : Dataset[mydataset] : Elapsed time for evaluation of 6000 events: \u001b[1;31m0.0125 sec\u001b[0m       \n",
      "--- MLP                      : Dataset[mydataset] : Creating weight file in xml format: \u001b[0;36mmydataset/weights/TMVAClassification_MLP.weights.xml\u001b[0m\n",
      "--- MLP                      : Dataset[mydataset] : Creating standalone response class: \u001b[0;36mmydataset/weights/TMVAClassification_MLP.class.C\u001b[0m\n",
      "--- MLP                      : Write special histos to file: TMVAOutput.root:/mydataset/Method_MLP/MLP\n",
      "--- Factory                  : Training finished\n",
      "--- Factory                  : \n",
      "--- Factory                  : Ranking input variables (method specific)...\n",
      "--- MLP                      : Ranking result (top variable is best ranked)\n",
      "--- MLP                      : -----------------------------\n",
      "--- MLP                      : Rank : Variable  : Importance\n",
      "--- MLP                      : -----------------------------\n",
      "--- MLP                      :    1 : var0      : 1.966e+01\n",
      "--- MLP                      :    2 : var1      : 1.383e+01\n",
      "--- MLP                      :    3 : var4      : 5.650e+00\n",
      "--- MLP                      :    4 : var3      : 4.027e+00\n",
      "--- MLP                      :    5 : var2      : 2.825e+00\n",
      "--- MLP                      :    6 : var5      : 1.832e+00\n",
      "--- MLP                      : -----------------------------\n",
      "--- Factory                  : \n",
      "--- Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "--- Factory                  : \n",
      "--- MethodBase               : Dataset[mydataset] : Reading weight file: \u001b[0;36mmydataset/weights/TMVAClassification_MLP.weights.xml\u001b[0m\n",
      "--- MLP                      : Dataset[mydataset] : Read method \"MLP\" of type \"MLP\"\n",
      "--- MLP                      : Dataset[mydataset] : MVA method was trained with TMVA Version: 4.2.1\n",
      "--- MLP                      : Dataset[mydataset] : MVA method was trained with ROOT Version: 6.07/07\n",
      "--- MLP                      : Building Network\n",
      "--- MLP                      : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"jstmva_1\" style=\"width: 800px; height:450px\"></div>\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'JsMVA':'https://rawgit.com/qati/GSOC16/master/src/js/JsMVA.min'\n",
       "        }\n",
       "    });\n",
       "    require(['JsMVA'],function(jsmva){\n",
       "        jsmva.drawNeuralNetwork('jstmva_1','{\"variables\": [\"var0\", \"var1\", \"var2\", \"var3\", \"var4\", \"var5\"], \"layout\": {\"layer_1\": {\"nneurons\": 12, \"neuron_10\": {\"nsynapses\": 1, \"weights\": [-1.010120061767279]}, \"neuron_0\": {\"nsynapses\": 1, \"weights\": [-0.6415959609735149]}, \"neuron_1\": {\"nsynapses\": 1, \"weights\": [1.157502900845923]}, \"neuron_2\": {\"nsynapses\": 1, \"weights\": [1.2493226882025956]}, \"neuron_3\": {\"nsynapses\": 1, \"weights\": [4.006327711552815]}, \"neuron_4\": {\"nsynapses\": 1, \"weights\": [0.5207299854773841]}, \"neuron_5\": {\"nsynapses\": 1, \"weights\": [0.7900623998932808]}, \"neuron_6\": {\"nsynapses\": 1, \"weights\": [-0.6149466195836132]}, \"neuron_7\": {\"nsynapses\": 1, \"weights\": [-3.5638883055208446]}, \"neuron_8\": {\"nsynapses\": 1, \"weights\": [-3.692543609500814]}, \"neuron_9\": {\"nsynapses\": 1, \"weights\": [0.6986535824264143]}, \"neuron_11\": {\"nsynapses\": 1, \"weights\": [-0.27443932657461845]}}, \"layer_0\": {\"nneurons\": 7, \"neuron_0\": {\"nsynapses\": 11, \"weights\": [-1.188542078172925, 0.36334329408263877, 1.6223469136138786, 8.28664865394176, -2.7466778891713894, -2.1292579167601673, -0.6435388834613436, 5.632365485167292, -2.19388144578363, -1.7810403469914382, -1.2627145805598594]}, \"neuron_1\": {\"nsynapses\": 11, \"weights\": [-1.4373549532273873, -2.9243528005252553, -0.845234114899702, -3.7601669129790034, 0.5721954270694212, -1.1916171507136841, 1.774155091396003, -2.481568540481081, 2.986709599164976, -1.2196376206306023, 0.7860936596546793]}, \"neuron_2\": {\"nsynapses\": 11, \"weights\": [1.4626968405668577, 1.4922026585634143, 0.1390210886747963, -0.08196004475287799, 1.2025520924423567, 0.35445749486005723, -1.5307619551439005, 0.7672830588585385, 0.4592432609053194, 2.230703041140452, -0.06513765872110591]}, \"neuron_3\": {\"nsynapses\": 11, \"weights\": [-0.42117712840123356, -0.23313163039935622, 0.3021982105531632, 3.942432691762532, 1.290420975572779, -1.411816700372112, 1.1439841142239946, 4.550368434122995, -0.28026878288583984, 1.6548926271836535, 0.9648861254156342]}, \"neuron_4\": {\"nsynapses\": 11, \"weights\": [-1.1342737117738968, -1.8111290073309791, 0.9735109213301975, 0.43163668459411886, 0.8687398583812446, 1.1104925303271442, 1.3686228021094615, -0.13285584429075098, -2.6725903494504637, 0.8342621898147459, -1.0982654379858485]}, \"neuron_5\": {\"nsynapses\": 11, \"weights\": [-1.063324270569455, -1.4583449536996358, -1.2913042219051472, -0.03831197009412337, 0.46863693685139546, -1.2701197507642537, 0.5707081674836019, -1.3500196239155036, 1.3924613493330211, 1.6652096327868842, 0.572441715320188]}, \"neuron_6\": {\"nsynapses\": 11, \"weights\": [0.536647151324193, -3.513375930038655, 2.8964223439337276, 6.37962504617177, -1.1314308163526938, -0.49068053283168844, 2.5707160590715765, 3.5270228787644764, 2.835566456446412, 0.499518217304017, -2.879582367061167]}}, \"nlayers\": \"3\", \"layer_2\": {\"neuron_0\": {\"nsynapses\": 0}, \"nneurons\": 1}}}');\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factory.DrawNeuralNetwork(\"mydataset\", \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
