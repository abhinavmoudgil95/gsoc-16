{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oproject.org/tiki-download_file.php?fileId=8&display&x=450&y=128\" width=\"200\" height=\"200\">\n",
    "<img src=\"http://gfif.udea.edu.co/root/tmva/img/tmva_logo.gif\" width=\"200\" height=\"200\">\n",
    "\n",
    "# Variance Threshold Transformation\n",
    "<hr style=\"border-top-width: 4px; border-top-color: #34609b;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In high energy physics and machine learning problems, we often encounter data which have large number of input variables. However to extract maximum information from the data, we need to select the relevant input variables for the multivariate classification and regression methods implemented in TMVA. Variance Threshold is a simple unsupervised variable selection method which automates this process. \n",
    "\n",
    "It computes weighted variance $\\sigma^2_V$ for each variable $V$ and ignores the ones whose variance doesn't meet a specific threshold. Weighted variance for each variable is defined as follows: \n",
    "$$\\sigma^2_V = \\frac{\\sum_{i=1}^N w_i (x_i - \\mu_V)^2}{\\sum_{i=1}^N w_i}$$\n",
    "\n",
    "where $N$ is the number of events in a dataset, $x_i$ denotes the value of variable for the $i$th event, $w_i$ is the weight of each event and $\\mu_V$ denotes the weighted mean of variable. \n",
    "$$\\mu_V = \\frac{\\sum_{i=1}^N w_i x_i}{\\sum_{i=1}^N w_i}$$\n",
    "\n",
    "A threshold $T$ for variance can be set by user otherwise default value of threshold is zero i.e. remove the variables which have same value in all the events. We get a new set of variables $S$ which can be formally defined as: \n",
    "\n",
    "$$S = \\{V  \\mid \\sigma^2_V > T \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook'],\n",
       "  function() {\n",
       "    IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};\n",
       "    console.log(\"JupyROOT - %%cpp magic configured\");\n",
       "  }\n",
       ");\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.07/07\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile, TMVA, TCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DataLoader and Factory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  : You are running ROOT Version: 6.07/07, Apr 1, 2016\n",
      "--- Factory                  : \n",
      "--- Factory                  : _/_/_/_/_/ _|      _|  _|      _|    _|_|   \n",
      "--- Factory                  :    _/      _|_|  _|_|  _|      _|  _|    _| \n",
      "--- Factory                  :   _/       _|  _|  _|  _|      _|  _|_|_|_| \n",
      "--- Factory                  :  _/        _|      _|    _|  _|    _|    _| \n",
      "--- Factory                  : _/         _|      _|      _|      _|    _| \n",
      "--- Factory                  : \n",
      "--- Factory                  : ___________TMVA Version 4.2.1, Feb 5, 2015\n",
      "--- Factory                  : \n"
     ]
    }
   ],
   "source": [
    "outputFile = TFile(\"VTOutput.root\", \"RECREATE\")\n",
    "inputFile  = TFile(\"../../datasets/mydataset.root\")\n",
    "\n",
    "TMVA.Tools.Instance()\n",
    "\n",
    "factory = TMVA.Factory(\"TMVAClassification\",\n",
    "                       outputFile,\n",
    "                       \"!V:ROC:!Correlations:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\")\n",
    "   \n",
    "loader1 = TMVA.DataLoader(\"mydataset\")\n",
    "\n",
    "# Adding variables to dataset\n",
    "loader1.AddVariable(\"var0\", 'F')\n",
    "loader1.AddVariable(\"var1\", 'F')\n",
    "loader1.AddVariable(\"var2\", 'F')\n",
    "loader1.AddVariable(\"var3 := var0-var1\", 'F')\n",
    "loader1.AddVariable(\"var4 := var0*var2\", 'F')\n",
    "loader1.AddVariable(\"var5 := var1+var2\", 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset from Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TMVAClassification       : Using input file: ../../datasets/mydataset.root\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Signal\"\t with internal class number 0\n",
      "--- Configurable             : Add Tree MyMCSig of type Signal with 5449 events\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Background\"\t with internal class number 1\n",
      "--- Configurable             : Add Tree MyMCBkg of type Background with 5449 events\n",
      "--- Configurable             : Preparing trees for training and testing...\n"
     ]
    }
   ],
   "source": [
    "print \"--- TMVAClassification       : Using input file:\", inputFile.GetName()\n",
    "   \n",
    "# Register the training and test trees\n",
    "tsignal     = inputFile.Get(\"MyMCSig\")\n",
    "tbackground = inputFile.Get(\"MyMCBkg\")\n",
    "     \n",
    "signalWeight     = 1.0\n",
    "backgroundWeight = 1.0\n",
    "    \n",
    "mycuts = TCut(\"\")\n",
    "mycutb = TCut(\"\")\n",
    "\n",
    "loader1.AddSignalTree(tsignal, signalWeight)\n",
    "loader1.AddBackgroundTree(tbackground, backgroundWeight)\n",
    "loader1.fSignalWeight = signalWeight\n",
    "loader1.fBackgroundWeight = backgroundWeight\n",
    "loader1.fTreeS = tsignal\n",
    "loader1.fTreeB = tbackground\n",
    "loader1.PrepareTrainingAndTestTree(mycuts,\n",
    "                                  mycutb,\n",
    "                                  \"nTrain_Signal=3000:nTrain_Background=3000:nTest_Signal=1449:nTest_Background=1449:SplitMode=Random:NormMode=NumEvents:!V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Variance Threshold \n",
    "\n",
    "After having dataset loaded in DataLoader with all the variables, we are now ready to apply Variance Threshold transformation. It is implemented in VarTransform method in [DataLoader](https://root.cern.ch/doc/master/classTMVA_1_1DataLoader.html) class. \n",
    "\n",
    "### Method Definition\n",
    "Parameters: Transformation definition string  \n",
    "Returns: DataLoader with selected subset of variables   \n",
    "\n",
    "Transformation defintion string **should only follow** either of the following formats otherwise method would raise an error.\n",
    "\n",
    "|String            | Description                                                            |\n",
    "|------------------|------------------------------------------------------------------------|\n",
    "|\"VT\"              | Select variables whose variance is above threshold value = 0 (Default) |\n",
    "|\"VT(float_value)\" | Select variables whose variance lies above float_value passed.         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataSetFactory           : Dataset[mydataset] : Splitmode is: \"RANDOM\" the mixmode is: \"SAMEASSPLITMODE\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create training and testing trees -- looping over class \"Signal\" ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight expression for class 'Signal': \"\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create training and testing trees -- looping over class \"Background\" ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight expression for class 'Background': \"\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Number of events in input trees (after possible flattening of arrays):\n",
      "--- DataSetFactory           : Dataset[mydataset] :     Signal      -- number of events       : 5449  / sum of weights: 5449\n",
      "--- DataSetFactory           : Dataset[mydataset] :     Background      -- number of events       : 5449  / sum of weights: 5449\n",
      "--- DataSetFactory           : Dataset[mydataset] :     Signal tree -- total number of entries: 5449\n",
      "--- DataSetFactory           : Dataset[mydataset] :     Background tree -- total number of entries: 5449\n",
      "--- DataSetFactory           : Dataset[mydataset] : Preselection: (will NOT affect number of requested training and testing events)\n",
      "--- DataSetFactory           : Dataset[mydataset] :     No preselection cuts applied on event classes\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight renormalisation mode: \"NumEvents\": renormalises all event classes \n",
      "--- DataSetFactory           : Dataset[mydataset] :  such that the effective (weighted) number of events in each class equals the respective \n",
      "--- DataSetFactory           : Dataset[mydataset] :  number of events (entries) that you demanded in PrepareTrainingAndTestTree(\"\",\"nTrain_Signal=.. )\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ... i.e. such that Sum[i=1..N_j]{w_i} = N_j, j=0,1,2...\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ... (note that N_j is the sum of TRAINING events (nTrain_j...with j=Signal,Background..\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor! )\n",
      "--- DataSetFactory           : Dataset[mydataset] : --> Rescale Signal event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[mydataset] : --> Rescale Background event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[mydataset] : Number of training and testing events after rescaling:\n",
      "--- DataSetFactory           : Dataset[mydataset] : ---------------------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create internal training tree\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create internal testing tree\n",
      "--- DataSetInfo              : Dataset[mydataset] : Correlation matrix (Signal):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :  var0var1var2var0-var1var0*var2var1+var2\n",
      "--- DataSetInfo              : var0:+1.000-0.008+0.011+0.852+0.922+0.000\n",
      "--- DataSetInfo              : var1:-0.008+1.000+0.010-0.531-0.004+0.811\n",
      "--- DataSetInfo              : var2:+0.011+0.010+1.000+0.004+0.335+0.593\n",
      "--- DataSetInfo              : var0-var1:+0.852-0.531+0.004+1.000+0.784-0.425\n",
      "--- DataSetInfo              : var0*var2:+0.922-0.004+0.335+0.784+1.000+0.192\n",
      "--- DataSetInfo              : var1+var2:+0.000+0.811+0.593-0.425+0.192+1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              : Dataset[mydataset] : Correlation matrix (Background):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :  var0var1var2var0-var1var0*var2var1+var2\n",
      "--- DataSetInfo              : var0:+1.000-0.008+0.008+0.650+0.670-0.001\n",
      "--- DataSetInfo              : var1:-0.008+1.000+0.009-0.766+0.001+0.738\n",
      "--- DataSetInfo              : var2:+0.008+0.009+1.000-0.002+0.696+0.682\n",
      "--- DataSetInfo              : var0-var1:+0.650-0.766-0.002+1.000+0.431-0.561\n",
      "--- DataSetInfo              : var0*var2:+0.670+0.001+0.696+0.431+1.000+0.471\n",
      "--- DataSetInfo              : var1+var2:-0.001+0.738+0.682-0.561+0.471+1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[mydataset] :  \n",
      "--- VarTransformHandler      : Number of events - 6000\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- VarTransformHandler      : VariablesVariance\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- VarTransformHandler      : var02.83513\n",
      "--- VarTransformHandler      : var12.02377\n",
      "--- VarTransformHandler      : var21.45872\n",
      "--- VarTransformHandler      : var0-var14.95813\n",
      "--- VarTransformHandler      : var0*var257.202\n",
      "--- VarTransformHandler      : var1+var23.14537\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- VarTransformHandler      : TargetsVariance\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- VarTransformHandler      : Set minNorm/maxNorm for variables to: \n",
      "--- VarTransformHandler      :     var0\t: [0.0433797\t, 9.99504\t] \n",
      "--- VarTransformHandler      :     var1\t: [9.9424e-05\t, 4.99673\t] \n",
      "--- VarTransformHandler      :     var2\t: [0.000886448\t, 4.99926\t] \n",
      "--- VarTransformHandler      :     var0-var1\t: [-4.44537\t, 9.96153\t] \n",
      "--- VarTransformHandler      :     var0*var2\t: [0.000883656\t, 48.22\t] \n",
      "--- VarTransformHandler      :     var1+var2\t: [0.14162\t, 9.87022\t] \n",
      "--- VarTransformHandler      : Set minNorm/maxNorm for targets to: \n",
      "--- VarTransformHandler      : Number of variables before transformation: 6\n",
      "--- VarTransformHandler      : Selecting variables whose variance is above threshold value = 2.95\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- VarTransformHandler      : Selected VariablesVariance\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- VarTransformHandler      : var0-var14.95813\n",
      "--- VarTransformHandler      : var0*var257.202\n",
      "--- VarTransformHandler      : var1+var23.14537\n",
      "--- VarTransformHandler      : ----------------------------------------------------------------\n",
      "--- Configurable             : Preparing trees for training and testing...\n",
      "--- DataSetInfo              : Dataset[default] : Added class \"Signal\"\t with internal class number 0\n",
      "--- DataSetInfo              : Dataset[default] : Added class \"Background\"\t with internal class number 1\n",
      "--- VarTransformHandler      : Number of variables after transformation: 3\n"
     ]
    }
   ],
   "source": [
    "loader2 = loader1.VarTransform(\"VT(2.95)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  : Booking method: \u001b[1mBDT\u001b[0m DataSet Name: \u001b[1mmydataset\u001b[0m\n",
      "--- Factory                  : Booking method: \u001b[1mMLP\u001b[0m DataSet Name: \u001b[1mmydataset\u001b[0m\n",
      "--- MLP                      : Dataset[mydataset] : Create Transformation \"N\" with events from all classes.\n",
      "--- Norm                     : Transformation, Variable selection : \n",
      "--- Norm                     : Input : variable 'var0' (index=0).   <---> Output : variable 'var0' (index=0).\n",
      "--- Norm                     : Input : variable 'var1' (index=1).   <---> Output : variable 'var1' (index=1).\n",
      "--- Norm                     : Input : variable 'var2' (index=2).   <---> Output : variable 'var2' (index=2).\n",
      "--- Norm                     : Input : variable 'var3' (index=3).   <---> Output : variable 'var3' (index=3).\n",
      "--- Norm                     : Input : variable 'var4' (index=4).   <---> Output : variable 'var4' (index=4).\n",
      "--- Norm                     : Input : variable 'var5' (index=5).   <---> Output : variable 'var5' (index=5).\n",
      "--- MLP                      : Building Network\n",
      "--- MLP                      : Initializing weights\n",
      "--- Factory                  : Booking method: \u001b[1mFisher\u001b[0m DataSet Name: \u001b[1mmydataset\u001b[0m\n",
      "--- Factory                  : Booking method: \u001b[1mSVM\u001b[0m DataSet Name: \u001b[1mmydataset\u001b[0m\n",
      "--- Factory                  : Booking method: \u001b[1mDNN\u001b[0m DataSet Name: \u001b[1mmydataset\u001b[0m\n",
      "--- Configurable             : Parsing option string: \n",
      "--- Configurable             : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
      "--- Configurable             : The following options are set:\n",
      "--- Configurable             : - By User:\n",
      "--- Configurable             :     <none>\n",
      "--- Configurable             : - Default:\n",
      "--- Configurable             :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "--- DNN                      : Parsing option string: \n",
      "--- DNN                      : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
      "--- DNN                      : The following options are set:\n",
      "--- DNN                      : - By User:\n",
      "--- DNN                      :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "--- DNN                      :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "--- DNN                      :     H: \"False\" [Print method-specific help message]\n",
      "--- DNN                      :     Layout: \"TANH|100,TANH|50,TANH|10,LINEAR\" [neural network layout]\n",
      "--- DNN                      :     ErrorStrategy: \"CROSSENTROPY\" [error strategy (regression: sum of squares; classification: crossentropy; multiclass: crossentropy/mutual exclusive cross entropy]\n",
      "--- DNN                      :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "--- DNN                      :     TrainingStrategy: \"LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\" [defines the training strategies]\n",
      "--- DNN                      : - Default:\n",
      "--- DNN                      :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "--- DNN                      :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "--- DNN                      :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "--- DNN                      :     SignalWeightsSum: \"1.000000e+03\" [Sum of weights of signal; Is used to compute the significance on the fly]\n",
      "--- DNN                      :     BackgroundWeightsSum: \"1.000000e+03\" [Sum of weights of background; Is used to compute the significance on the fly]\n",
      "--- DNN                      : Dataset[mydataset] : Create Transformation \"G\" with events from all classes.\n",
      "--- Gauss                    : Transformation, Variable selection : \n",
      "--- Gauss                    : Input : variable 'var0' (index=0).   <---> Output : variable 'var0' (index=0).\n",
      "--- Gauss                    : Input : variable 'var1' (index=1).   <---> Output : variable 'var1' (index=1).\n",
      "--- Gauss                    : Input : variable 'var2' (index=2).   <---> Output : variable 'var2' (index=2).\n",
      "--- Gauss                    : Input : variable 'var3' (index=3).   <---> Output : variable 'var3' (index=3).\n",
      "--- Gauss                    : Input : variable 'var4' (index=4).   <---> Output : variable 'var4' (index=4).\n",
      "--- Gauss                    : Input : variable 'var5' (index=5).   <---> Output : variable 'var5' (index=5).\n"
     ]
    }
   ],
   "source": [
    "# #Boosted Decision Trees\n",
    "# factory.BookMethod(loader1,TMVA.Types.kBDT, \"BDT\",\n",
    "#                    \"!V:NTrees=200:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n",
    "\n",
    "# #Multi-Layer Perceptron (Neural Network)\n",
    "# factory.BookMethod(loader1, TMVA.Types.kMLP, \"MLP\",\n",
    "#                    \"!H:!V:NeuronType=tanh:VarTransform=N:NCycles=100:HiddenLayers=N+5:TestRate=5:!UseRegulator\" );\n",
    "\n",
    "# #Fisher Discriminant\n",
    "# factory.BookMethod(loader1, TMVA.Types.kFisher, \"Fisher\",\n",
    "# \"H:!V:Fisher:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=60:\\\n",
    "# NsmoothMVAPdf=10\" );\n",
    "\n",
    "# #Support Vector Machine\n",
    "# factory.BookMethod(loader1, TMVA.Types.kSVM, \"SVM\", \"Gamma=0.25:Tol=0.001\" );\n",
    "\n",
    "#DNN \n",
    "layoutString = \"Layout=TANH|100,TANH|50,TANH|10,LINEAR\"\n",
    "training0 = \"LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True\"\n",
    "training1 = \"LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
    "trainingStrategyString = \"TrainingStrategy=\"\n",
    "trainingStrategyString += training0 + \"|\" + training1\n",
    "nnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM\"\n",
    "nnOptions += \":\"\n",
    "nnOptions += layoutString\n",
    "nnOptions += \":\"\n",
    "nnOptions += trainingStrategyString\n",
    "factory.BookMethod(loader1, TMVA.Types.kDNN, \"DNN\", nnOptions );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  : Booking method: \u001b[1mBDT\u001b[0m DataSet Name: \u001b[1mtransformed_dataset\u001b[0m\n",
      "--- DataSetFactory           : Dataset[default] : Splitmode is: \"RANDOM\" the mixmode is: \"SAMEASSPLITMODE\"\n",
      "--- DataSetFactory           : Dataset[default] : Create training and testing trees -- looping over class \"Signal\" ...\n",
      "--- DataSetFactory           : Dataset[default] : Weight expression for class 'Signal': \"\"\n",
      "--- DataSetFactory           : Dataset[default] : Create training and testing trees -- looping over class \"Background\" ...\n",
      "--- DataSetFactory           : Dataset[default] : Weight expression for class 'Background': \"\"\n",
      "--- DataSetFactory           : Dataset[default] : Number of events in input trees (after possible flattening of arrays):\n",
      "--- DataSetFactory           : Dataset[default] :     Signal      -- number of events       : 5449  / sum of weights: 5449\n",
      "--- DataSetFactory           : Dataset[default] :     Background      -- number of events       : 5449  / sum of weights: 5449\n",
      "--- DataSetFactory           : Dataset[default] :     Signal tree -- total number of entries: 5449\n",
      "--- DataSetFactory           : Dataset[default] :     Background tree -- total number of entries: 5449\n",
      "--- DataSetFactory           : Dataset[default] : Preselection: (will NOT affect number of requested training and testing events)\n",
      "--- DataSetFactory           : Dataset[default] :     No preselection cuts applied on event classes\n",
      "--- DataSetFactory           : Dataset[default] : Weight renormalisation mode: \"NumEvents\": renormalises all event classes \n",
      "--- DataSetFactory           : Dataset[default] :  such that the effective (weighted) number of events in each class equals the respective \n",
      "--- DataSetFactory           : Dataset[default] :  number of events (entries) that you demanded in PrepareTrainingAndTestTree(\"\",\"nTrain_Signal=.. )\n",
      "--- DataSetFactory           : Dataset[default] :  ... i.e. such that Sum[i=1..N_j]{w_i} = N_j, j=0,1,2...\n",
      "--- DataSetFactory           : Dataset[default] :  ... (note that N_j is the sum of TRAINING events (nTrain_j...with j=Signal,Background..\n",
      "--- DataSetFactory           : Dataset[default] :  ..... Testing events are not renormalised nor included in the renormalisation factor! )\n",
      "--- DataSetFactory           : Dataset[default] : --> Rescale Signal event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[default] : --> Rescale Background event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[default] : Number of training and testing events after rescaling:\n",
      "--- DataSetFactory           : Dataset[default] : ---------------------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[default] : Signal -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[default] : Signal -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[default] : Signal -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[default] : Background -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[default] : Background -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[default] : Background -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[default] : Create internal training tree\n",
      "--- DataSetFactory           : Dataset[default] : Create internal testing tree\n",
      "--- DataSetInfo              : Dataset[default] : Correlation matrix (Signal):\n",
      "--- DataSetInfo              : ----------------------------------------\n",
      "--- DataSetInfo              :  var0-var1var0*var2var1+var2\n",
      "--- DataSetInfo              : var0-var1:+1.000+0.784-0.425\n",
      "--- DataSetInfo              : var0*var2:+0.784+1.000+0.192\n",
      "--- DataSetInfo              : var1+var2:-0.425+0.192+1.000\n",
      "--- DataSetInfo              : ----------------------------------------\n",
      "--- DataSetInfo              : Dataset[default] : Correlation matrix (Background):\n",
      "--- DataSetInfo              : ----------------------------------------\n",
      "--- DataSetInfo              :  var0-var1var0*var2var1+var2\n",
      "--- DataSetInfo              : var0-var1:+1.000+0.431-0.561\n",
      "--- DataSetInfo              : var0*var2:+0.431+1.000+0.471\n",
      "--- DataSetInfo              : var1+var2:-0.561+0.471+1.000\n",
      "--- DataSetInfo              : ----------------------------------------\n",
      "--- DataSetFactory           : Dataset[default] :  \n",
      "--- Factory                  : Booking method: \u001b[1mMLP\u001b[0m DataSet Name: \u001b[1mtransformed_dataset\u001b[0m\n",
      "--- MLP                      : Dataset[default] : Create Transformation \"N\" with events from all classes.\n",
      "--- Norm                     : Transformation, Variable selection : \n",
      "--- Norm                     : Input : variable 'var0-var1' (index=0).   <---> Output : variable 'var0-var1' (index=0).\n",
      "--- Norm                     : Input : variable 'var0*var2' (index=1).   <---> Output : variable 'var0*var2' (index=1).\n",
      "--- Norm                     : Input : variable 'var1+var2' (index=2).   <---> Output : variable 'var1+var2' (index=2).\n",
      "--- MLP                      : Building Network\n",
      "--- MLP                      : Initializing weights\n",
      "--- Factory                  : Booking method: \u001b[1mFisher\u001b[0m DataSet Name: \u001b[1mtransformed_dataset\u001b[0m\n",
      "--- Factory                  : Booking method: \u001b[1mSVM\u001b[0m DataSet Name: \u001b[1mtransformed_dataset\u001b[0m\n",
      "--- Factory                  : Booking method: \u001b[1mDNN\u001b[0m DataSet Name: \u001b[1mtransformed_dataset\u001b[0m\n",
      "--- Configurable             : Parsing option string: \n",
      "--- Configurable             : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
      "--- Configurable             : The following options are set:\n",
      "--- Configurable             : - By User:\n",
      "--- Configurable             :     <none>\n",
      "--- Configurable             : - Default:\n",
      "--- Configurable             :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "--- DNN                      : Parsing option string: \n",
      "--- DNN                      : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
      "--- DNN                      : The following options are set:\n",
      "--- DNN                      : - By User:\n",
      "--- DNN                      :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "--- DNN                      :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "--- DNN                      :     H: \"False\" [Print method-specific help message]\n",
      "--- DNN                      :     Layout: \"TANH|100,TANH|50,TANH|10,LINEAR\" [neural network layout]\n",
      "--- DNN                      :     ErrorStrategy: \"CROSSENTROPY\" [error strategy (regression: sum of squares; classification: crossentropy; multiclass: crossentropy/mutual exclusive cross entropy]\n",
      "--- DNN                      :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "--- DNN                      :     TrainingStrategy: \"LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\" [defines the training strategies]\n",
      "--- DNN                      : - Default:\n",
      "--- DNN                      :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "--- DNN                      :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "--- DNN                      :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "--- DNN                      :     SignalWeightsSum: \"1.000000e+03\" [Sum of weights of signal; Is used to compute the significance on the fly]\n",
      "--- DNN                      :     BackgroundWeightsSum: \"1.000000e+03\" [Sum of weights of background; Is used to compute the significance on the fly]\n",
      "--- DNN                      : Dataset[default] : Create Transformation \"G\" with events from all classes.\n",
      "--- Gauss                    : Transformation, Variable selection : \n",
      "--- Gauss                    : Input : variable 'var0-var1' (index=0).   <---> Output : variable 'var0-var1' (index=0).\n",
      "--- Gauss                    : Input : variable 'var0*var2' (index=1).   <---> Output : variable 'var0*var2' (index=1).\n",
      "--- Gauss                    : Input : variable 'var1+var2' (index=2).   <---> Output : variable 'var1+var2' (index=2).\n"
     ]
    }
   ],
   "source": [
    "# #Boosted Decision Trees\n",
    "# factory.BookMethod(loader2,TMVA.Types.kBDT, \"BDT\",\n",
    "#                    \"!V:NTrees=200:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n",
    "\n",
    "# #Multi-Layer Perceptron (Neural Network)\n",
    "# factory.BookMethod(loader2, TMVA.Types.kMLP, \"MLP\",\n",
    "#                    \"!H:!V:NeuronType=tanh:VarTransform=N:NCycles=100:HiddenLayers=N+5:TestRate=5:!UseRegulator\" );\n",
    "\n",
    "# #Fisher Discriminant\n",
    "# factory.BookMethod(loader2, TMVA.Types.kFisher, \"Fisher\",\n",
    "# \"H:!V:Fisher:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=60:\\\n",
    "# NsmoothMVAPdf=10\" );\n",
    "\n",
    "# #Support Vector Machine\n",
    "# factory.BookMethod(loader2, TMVA.Types.kSVM, \"SVM\", \"Gamma=0.25:Tol=0.001\" );\n",
    "\n",
    "#DNN \n",
    "layoutString = \"Layout=TANH|100,TANH|50,TANH|10,LINEAR\"\n",
    "training0 = \"LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True\"\n",
    "training1 = \"LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
    "trainingStrategyString = \"TrainingStrategy=\"\n",
    "trainingStrategyString += training0 + \"|\" + training1\n",
    "nnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM\"\n",
    "nnOptions += \":\"\n",
    "nnOptions += layoutString\n",
    "nnOptions += \":\"\n",
    "nnOptions += trainingStrategyString\n",
    "factory.BookMethod(loader2, TMVA.Types.kDNN, \"DNN\", nnOptions );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factory.TestAllMethods()\n",
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "c1 = factory.VarTransformROCPlot(loader1, loader2);\n",
    "c1.Draw();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
