{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oproject.org/tiki-download_file.php?fileId=8&display&x=450&y=128\" width=\"200\" height=\"200\">\n",
    "<img src=\"http://gfif.udea.edu.co/root/tmva/img/tmva_logo.gif\" width=\"200\" height=\"200\">\n",
    "# Autoencoder Variable Transformation\n",
    "<hr style=\"border-top-width: 4px; border-top-color: #34609b;\"> \n",
    "Notebook by Abhinav Moudgil and Neural Network Visualisation by Attila Bagoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PATH_TO_JSMVA_FOLDER=\"/Users/testuser/gsoc-2016/jsMVA/src/python/\"\n",
    "sys.path.append(os.path.expanduser(PATH_TO_JSMVA_FOLDER))\n",
    "import JsMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook'],\n",
       "  function() {\n",
       "    IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};\n",
       "    console.log(\"JupyROOT - %%cpp magic configured\");\n",
       "  }\n",
       ");\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.07/07\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile, TMVA, TCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%jsmva on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Factory                  : You are running ROOT Version: 6.07/07, Apr 1, 2016\n",
      "--- Factory                  : \n",
      "--- Factory                  : _/_/_/_/_/ _|      _|  _|      _|    _|_|   \n",
      "--- Factory                  :    _/      _|_|  _|_|  _|      _|  _|    _| \n",
      "--- Factory                  :   _/       _|  _|  _|  _|      _|  _|_|_|_| \n",
      "--- Factory                  :  _/        _|      _|    _|  _|    _|    _| \n",
      "--- Factory                  : _/         _|      _|      _|      _|    _| \n",
      "--- Factory                  : \n",
      "--- Factory                  : ___________TMVA Version 4.2.1, Feb 5, 2015\n",
      "--- Factory                  : \n"
     ]
    }
   ],
   "source": [
    "outputFile = TFile(\"TMVAOutput.root\", \"RECREATE\")\n",
    "inputFile  = TFile(\"../datasets/mydataset.root\")\n",
    "\n",
    "TMVA.Tools.Instance()\n",
    "\n",
    "factory = TMVA.Factory(\"TMVAClassification\",\n",
    "                       outputFile,\n",
    "                       \"!V:ROC:!Correlations:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\")\n",
    "   \n",
    "loader = TMVA.DataLoader(\"mydataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding variables to dataset\n",
    "loader.AddVariable(\"var0\", 'F')\n",
    "loader.AddVariable(\"var1\", 'F')\n",
    "loader.AddVariable(\"var2\", 'F')\n",
    "loader.AddVariable(\"var3 := var0-var1\", 'F')\n",
    "loader.AddVariable(\"var4 := var0*var2\", 'F')\n",
    "loader.AddVariable(\"var5 := var1+var2\", 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TMVAClassification       : Using input file: ../datasets/mydataset.root\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Signal\"\t with internal class number 0\n",
      "--- mydataset                : Add Tree MyMCSig of type Signal with 5449 events\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Background\"\t with internal class number 1\n",
      "--- mydataset                : Add Tree MyMCBkg of type Background with 5449 events\n",
      "--- mydataset                : Preparing trees for training and testing...\n"
     ]
    }
   ],
   "source": [
    "print \"--- TMVAClassification       : Using input file:\", inputFile.GetName()\n",
    "   \n",
    "# Register the training and test trees\n",
    "\n",
    "tsignal     = inputFile.Get(\"MyMCSig\")\n",
    "tbackground = inputFile.Get(\"MyMCBkg\")\n",
    "     \n",
    "signalWeight     = 1.0\n",
    "backgroundWeight = 1.0\n",
    "\n",
    "mycuts = TCut(\"\")\n",
    "mycutb = TCut(\"\")\n",
    "\n",
    "loader.AddSignalTree(tsignal, signalWeight)\n",
    "loader.AddBackgroundTree(tbackground, backgroundWeight)\n",
    "loader.fSignalWeight = signalWeight\n",
    "loader.fBackgroundWeight = backgroundWeight\n",
    "loader.fTreeS = tsignal\n",
    "loader.fTreeB = tbackground\n",
    "loader.PrepareTrainingAndTestTree(mycuts,\n",
    "                                  mycutb,\n",
    "                                  \"nTrain_Signal=3000:nTrain_Background=3000:nTest_Signal=1449:nTest_Background=1449:SplitMode=Random:NormMode=NumEvents:!V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataSetFactory           : Dataset[mydataset] : Splitmode is: \"RANDOM\" the mixmode is: \"SAMEASSPLITMODE\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create training and testing trees -- looping over class \"Signal\" ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight expression for class 'Signal': \"\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create training and testing trees -- looping over class \"Background\" ...\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight expression for class 'Background': \"\"\n",
      "--- DataSetFactory           : Dataset[mydataset] : Number of events in input trees (after possible flattening of arrays):\n",
      "--- DataSetFactory           : Dataset[mydataset] :     Signal          -- number of events       : 5449   / sum of weights: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] :     Background      -- number of events       : 5449   / sum of weights: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] :     Signal     tree -- total number of entries: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] :     Background tree -- total number of entries: 5449 \n",
      "--- DataSetFactory           : Dataset[mydataset] : Preselection: (will NOT affect number of requested training and testing events)\n",
      "--- DataSetFactory           : Dataset[mydataset] :     No preselection cuts applied on event classes\n",
      "--- DataSetFactory           : Dataset[mydataset] : Weight renormalisation mode: \"NumEvents\": renormalises all event classes \n",
      "--- DataSetFactory           : Dataset[mydataset] :  such that the effective (weighted) number of events in each class equals the respective \n",
      "--- DataSetFactory           : Dataset[mydataset] :  number of events (entries) that you demanded in PrepareTrainingAndTestTree(\"\",\"nTrain_Signal=.. )\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ... i.e. such that Sum[i=1..N_j]{w_i} = N_j, j=0,1,2...\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ... (note that N_j is the sum of TRAINING events (nTrain_j...with j=Signal,Background..\n",
      "--- DataSetFactory           : Dataset[mydataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor! )\n",
      "--- DataSetFactory           : Dataset[mydataset] : --> Rescale Signal     event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[mydataset] : --> Rescale Background event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[mydataset] : Number of training and testing events after rescaling:\n",
      "--- DataSetFactory           : Dataset[mydataset] : ---------------------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal     -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal     -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Signal     -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- training events            : 3000 (sum of weights: 3000) - requested were 3000 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- testing events             : 1449 (sum of weights: 1449) - requested were 1449 events\n",
      "--- DataSetFactory           : Dataset[mydataset] : Background -- training and testing events: 4449 (sum of weights: 4449)\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create internal training tree\n",
      "--- DataSetFactory           : Dataset[mydataset] : Create internal testing tree\n",
      "--- DataSetInfo              : Dataset[mydataset] : Correlation matrix (Signal):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :               var0    var1    var2 var0-var1 var0*var2 var1+var2\n",
      "--- DataSetInfo              :      var0:  +1.000  -0.008  +0.011    +0.852    +0.922    +0.000\n",
      "--- DataSetInfo              :      var1:  -0.008  +1.000  +0.010    -0.531    -0.004    +0.811\n",
      "--- DataSetInfo              :      var2:  +0.011  +0.010  +1.000    +0.004    +0.335    +0.593\n",
      "--- DataSetInfo              : var0-var1:  +0.852  -0.531  +0.004    +1.000    +0.784    -0.425\n",
      "--- DataSetInfo              : var0*var2:  +0.922  -0.004  +0.335    +0.784    +1.000    +0.192\n",
      "--- DataSetInfo              : var1+var2:  +0.000  +0.811  +0.593    -0.425    +0.192    +1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              : Dataset[mydataset] : Correlation matrix (Background):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :               var0    var1    var2 var0-var1 var0*var2 var1+var2\n",
      "--- DataSetInfo              :      var0:  +1.000  -0.008  +0.008    +0.650    +0.670    -0.001\n",
      "--- DataSetInfo              :      var1:  -0.008  +1.000  +0.009    -0.766    +0.001    +0.738\n",
      "--- DataSetInfo              :      var2:  +0.008  +0.009  +1.000    -0.002    +0.696    +0.682\n",
      "--- DataSetInfo              : var0-var1:  +0.650  -0.766  -0.002    +1.000    +0.431    -0.561\n",
      "--- DataSetInfo              : var0*var2:  +0.670  +0.001  +0.696    +0.431    +1.000    +0.471\n",
      "--- DataSetInfo              : var1+var2:  -0.001  +0.738  +0.682    -0.561    +0.471    +1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[mydataset] :  \n",
      "--- mydataset                : ----------------------------------------------------------------\n",
      "--- mydataset                : Variables        Variance  \n",
      "--- mydataset                : ----------------------------------------------------------------\n",
      "--- mydataset                : var0             2.8351           \n",
      "--- mydataset                : var1             2.0238           \n",
      "--- mydataset                : var2             1.4587           \n",
      "--- mydataset                : var0-var1        4.9581           \n",
      "--- mydataset                : var0*var2        57.202           \n",
      "--- mydataset                : var1+var2        3.1454           \n",
      "--- mydataset                : ----------------------------------------------------------------\n",
      "--- mydataset                : Targets Variance  \n",
      "--- mydataset                : ----------------------------------------------------------------\n",
      "--- mydataset                : Set minNorm/maxNorm for variables to: \n",
      "--- mydataset                :     var0\t: [0.0434\t, 10\t] \n",
      "--- mydataset                :     var1\t: [9.94e-05\t, 5\t] \n",
      "--- mydataset                :     var2\t: [0.000886\t, 5\t] \n",
      "--- mydataset                :     var0-var1\t: [-4.45\t, 9.96\t] \n",
      "--- mydataset                :     var0*var2\t: [0.000884\t, 48.2\t] \n",
      "--- mydataset                :     var1+var2\t: [0.142\t, 9.87\t] \n",
      "--- mydataset                : Set minNorm/maxNorm for targets to: \n"
     ]
    }
   ],
   "source": [
    "loader.CalcNorm()\n",
    "# factory.BookMethod(loader,\n",
    "#                    TMVA.Types.kMLP,\n",
    "#                    \"MLP\",\n",
    "#                    \"!V:NeuronType=tanh:VarTransform=N:NCycles=150:HiddenLayers=N+5:TestRate=5:!UseRegulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- mydataset                : [AE Transform] indexLayer = 1\n",
      "--- mydataset                : [AE Transform] Pretraining = false\n",
      "--- mydataset                : Preparing DataLoader for Autoencoder Transform DNN Training\n",
      "--- DataSetInfo              : Dataset[ae_transform_dataset] : Added class \"Regression\"\t with internal class number 0\n",
      "--- ae_transform_dataset     : Add Tree Dataset of type Regression with 6000 events\n",
      "--- DataSetInfo              : Dataset[ae_transform_dataset] : Class index : 0  name : Regression\n",
      "--- DNN                      : Parsing option string: \n",
      "--- DNN                      : ... \"!H:V:ErrorStrategy=SUMOFSQUARES:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|3,LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\"\n",
      "--- DNN                      : The following options are set:\n",
      "--- DNN                      : - By User:\n",
      "--- DNN                      :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "--- DNN                      :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "--- DNN                      :     H: \"False\" [Print method-specific help message]\n",
      "--- DNN                      :     Layout: \"TANH|3,LINEAR\" [neural network layout]\n",
      "--- DNN                      :     ErrorStrategy: \"SUMOFSQUARES\" [error strategy (regression: sum of squares; classification: crossentropy; multiclass: crossentropy/mutual exclusive cross entropy]\n",
      "--- DNN                      :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "--- DNN                      :     TrainingStrategy: \"LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1\" [defines the training strategies]\n",
      "--- DNN                      : - Default:\n",
      "--- DNN                      :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "--- DNN                      :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "--- DNN                      :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "--- DNN                      :     SignalWeightsSum: \"1.000000e+03\" [Sum of weights of signal; Is used to compute the significance on the fly]\n",
      "--- DNN                      :     BackgroundWeightsSum: \"1.000000e+03\" [Sum of weights of background; Is used to compute the significance on the fly]\n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Create Transformation \"G\" with events from all classes.\n",
      "--- Gauss                    : Transformation, Variable selection : \n",
      "--- Gauss                    : Input : variable 'var0' (index=0).   <---> Output : variable 'var0' (index=0).\n",
      "--- Gauss                    : Input : variable 'var1' (index=1).   <---> Output : variable 'var1' (index=1).\n",
      "--- Gauss                    : Input : variable 'var2' (index=2).   <---> Output : variable 'var2' (index=2).\n",
      "--- Gauss                    : Input : variable 'var0-var1' (index=3).   <---> Output : variable 'var0-var1' (index=3).\n",
      "--- Gauss                    : Input : variable 'var0*var2' (index=4).   <---> Output : variable 'var0*var2' (index=4).\n",
      "--- Gauss                    : Input : variable 'var1+var2' (index=5).   <---> Output : variable 'var1+var2' (index=5).\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Splitmode is: \"RANDOM\" the mixmode is: \"SAMEASSPLITMODE\"\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Create training and testing trees -- looping over class \"Regression\" ...\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Weight expression for class 'Regression': \"\"\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Number of events in input trees (after possible flattening of arrays):\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :     Regression      -- number of events       : 6000   / sum of weights: 6000 \n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :     Regression tree -- total number of entries: 6000 \n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Preselection: (will NOT affect number of requested training and testing events)\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :     No preselection cuts applied on event classes\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Weight renormalisation mode: \"EqualNumEvents\": renormalises all event classes ...\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :  such that the effective (weighted) number of events in each class is the same \n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :  (and equals the number of events (entries) given for class=0 )\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : ... i.e. such that Sum[i=1..N_j]{w_i} = N_classA, j=classA, classB, ...\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : ... (note that N_j is the sum of TRAINING events\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor!)\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : --> Rescale Regression event weights by factor: 1\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Number of training and testing events after rescaling:\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : ---------------------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Regression -- training events            : 3000 (sum of weights: 3000) - requested were 0 events\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Regression -- testing events             : 3000 (sum of weights: 3000) - requested were 0 events\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Regression -- training and testing events: 6000 (sum of weights: 6000)\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Create internal training tree\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] : Create internal testing tree\n",
      "--- DataSetInfo              : Dataset[ae_transform_dataset] : Correlation matrix (Regression):\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetInfo              :               var0    var1    var2 var0-var1 var0*var2 var1+var2\n",
      "--- DataSetInfo              :      var0:  +1.000  -0.009  +0.014    +0.770    +0.842    +0.002\n",
      "--- DataSetInfo              :      var1:  -0.009  +1.000  -0.105    -0.645    -0.058    +0.732\n",
      "--- DataSetInfo              :      var2:  +0.014  -0.105  +1.000    +0.077    +0.493    +0.601\n",
      "--- DataSetInfo              : var0-var1:  +0.770  -0.645  +0.077    +1.000    +0.680    -0.466\n",
      "--- DataSetInfo              : var0*var2:  +0.842  -0.058  +0.493    +0.680    +1.000    +0.291\n",
      "--- DataSetInfo              : var1+var2:  +0.002  +0.732  +0.601    -0.466    +0.291    +1.000\n",
      "--- DataSetInfo              : ----------------------------------------------------------------\n",
      "--- DataSetFactory           : Dataset[ae_transform_dataset] :  \n",
      "--- Gauss                    : Preparing the Gaussian transformation...\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            :  Variable         Mean         RMS   [        Min         Max ]\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            :      var0:   0.022158     1.0136   [    -2.8184     5.7307 ]\n",
      "--- TFHandler_DNN            :      var1:   0.023891     1.0219   [    -2.8029     5.7307 ]\n",
      "--- TFHandler_DNN            :      var2:   0.023205     1.0198   [    -2.8181     5.7307 ]\n",
      "--- TFHandler_DNN            : var0-var1:   0.022254     1.0117   [    -2.8186     5.7307 ]\n",
      "--- TFHandler_DNN            : var0*var2:   0.022862     1.0176   [    -2.8184     5.7307 ]\n",
      "--- TFHandler_DNN            : var1+var2:   0.020797     1.0103   [    -2.8185     5.7307 ]\n",
      "--- TFHandler_DNN            :      var0:     3.0704     1.7084   [   0.086018     9.9950 ]\n",
      "--- TFHandler_DNN            :      var1:     1.5613     1.4278   [ 9.9424e-05     4.9967 ]\n",
      "--- TFHandler_DNN            :      var2:     3.5123     1.2174   [   0.013488     4.9992 ]\n",
      "--- TFHandler_DNN            : var0-var1:     1.5091     2.2367   [    -4.4454     9.9365 ]\n",
      "--- TFHandler_DNN            : var0*var2:     10.812     7.6387   [   0.022988     48.220 ]\n",
      "--- TFHandler_DNN            : var1+var2:     5.0736     1.7766   [    0.25497     9.7770 ]\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Begin training\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            :  Variable         Mean         RMS   [        Min         Max ]\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            :      var0:   0.022158     1.0136   [    -2.8184     5.7307 ]\n",
      "--- TFHandler_DNN            :      var1:   0.023891     1.0219   [    -2.8029     5.7307 ]\n",
      "--- TFHandler_DNN            :      var2:   0.023205     1.0198   [    -2.8181     5.7307 ]\n",
      "--- TFHandler_DNN            : var0-var1:   0.022254     1.0117   [    -2.8186     5.7307 ]\n",
      "--- TFHandler_DNN            : var0*var2:   0.022862     1.0176   [    -2.8184     5.7307 ]\n",
      "--- TFHandler_DNN            : var1+var2:   0.020797     1.0103   [    -2.8185     5.7307 ]\n",
      "--- TFHandler_DNN            :      var0:     3.0704     1.7084   [   0.086018     9.9950 ]\n",
      "--- TFHandler_DNN            :      var1:     1.5613     1.4278   [ 9.9424e-05     4.9967 ]\n",
      "--- TFHandler_DNN            :      var2:     3.5123     1.2174   [   0.013488     4.9992 ]\n",
      "--- TFHandler_DNN            : var0-var1:     1.5091     2.2367   [    -4.4454     9.9365 ]\n",
      "--- TFHandler_DNN            : var0*var2:     10.812     7.6387   [   0.022988     48.220 ]\n",
      "--- TFHandler_DNN            : var1+var2:     5.0736     1.7766   [    0.25497     9.7770 ]\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            :  Variable         Mean         RMS   [        Min         Max ]\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- TFHandler_DNN            :      var0:   0.017183    0.99701   [    -3.0585     5.7307 ]\n",
      "--- TFHandler_DNN            :      var1:   0.036254     1.0226   [    -2.7487     5.7307 ]\n",
      "--- TFHandler_DNN            :      var2:   0.038710    0.99923   [    -2.9742     5.7307 ]\n",
      "--- TFHandler_DNN            : var0-var1:   0.012348     1.0153   [    -2.5811     5.7307 ]\n",
      "--- TFHandler_DNN            : var0*var2:   0.032623    0.98750   [    -2.9436     5.7307 ]\n",
      "--- TFHandler_DNN            : var1+var2:   0.038523    0.99842   [    -3.5603     5.7307 ]\n",
      "--- TFHandler_DNN            :      var0:     3.0472     1.6587   [   0.043380     9.9950 ]\n",
      "--- TFHandler_DNN            :      var1:     1.5683     1.4174   [ 0.00028976     4.9932 ]\n",
      "--- TFHandler_DNN            :      var2:     3.5400     1.1979   [ 0.00088645     4.9993 ]\n",
      "--- TFHandler_DNN            : var0-var1:     1.4789     2.2165   [    -3.9769     9.9615 ]\n",
      "--- TFHandler_DNN            : var0*var2:     10.851     7.4869   [ 0.00088366     48.019 ]\n",
      "--- TFHandler_DNN            : var1+var2:     5.1083     1.7703   [    0.14162     9.8702 ]\n",
      "--- TFHandler_DNN            : ----------------------------------------------------------------\n",
      "--- DNN                      : Add Layer with 3 nodes.\n",
      "--- DNN                      : Add Layer with 6 nodes.\n",
      "--- DNN                      : \n",
      "--- DNN                      : Total number of Synapses = 39\n",
      "--- DNN                      : Training with learning rate = 0.1, momentum = 0, repetitions = 1\n",
      "--- DNN                      : Drop configuration\n",
      "--- DNN                      :     drop repetitions = 1\n",
      "--- DNN                      :     Layer 0 = 0\n",
      "--- DNN                      :     Layer 1 = 0.5\n",
      "--- DNN                      :     Layer 2 = 0.5\n",
      "--- DNN                      :     Layer 3 = 0.5\n",
      "--- DNN                      : \n",
      "\n",
      "learning rate reduced to 0.05\n",
      "\n",
      "learning rate reduced to 0.025\n",
      "\n",
      "learning rate reduced to 0.0125\n",
      "\n",
      "\n",
      "lleeaarrnniinngg  rraattee  rreedduucceedd  ttoo  00..000033112255\n",
      "\n",
      "\n",
      "learning rate reduced to 0.0015625\n",
      "\n",
      "learning rate reduced to 0.00078125\n",
      "--- DNN                      : \n",
      "--- DNN                      : Training with learning rate = 0.01, momentum = 0.5, repetitions = 1\n",
      "--- DNN                      : Drop configuration\n",
      "--- DNN                      :     drop repetitions = 1\n",
      "--- DNN                      :     Layer 0 = 0\n",
      "--- DNN                      :     Layer 1 = 0.1\n",
      "--- DNN                      :     Layer 2 = 0.1\n",
      "--- DNN                      :     Layer 3 = 0.1\n",
      "--- DNN                      : \n",
      "--- DNN                      : \n",
      "--- DNN                      : Dataset[ae_transform_dataset] : End of training                                              \n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Elapsed time for training with 3000 events: \u001b[1;31m46.7 sec\u001b[0m         \n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Create MVA output for Dataset[ae_transform_dataset] : regression on training sample\n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Create results for training\n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Evaluation of DNN on training sample\n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Elapsed time for evaluation of 3000 events: \u001b[1;31m0.0373 sec\u001b[0m       \n",
      "--- ResultsRegressionDNN     : Create variable histograms\n",
      "--- ResultsRegressionDNN     : Create regression target histograms\n",
      "--- ResultsRegressionDNN     : Create regression average deviation\n",
      "--- ResultsRegressionDNN     : Results created\n",
      "--- DNN                      : Dataset[ae_transform_dataset] : Creating weight file in xml format: \u001b[0;36mae_transform_dataset/weights/TMVARegression_DNN.weights.xml\u001b[0m\n",
      "--- DNN                      : TMVAOutput.root:/ae_transform_dataset/Method_DNN/DNN\n",
      "--- mydataset                : Training finished\n",
      "--- mydataset                : Weight file name: ae_transform_dataset/weights/TMVARegression_DNN.weights.xml\n",
      "--- mydataset                : [AE Transform] Total number of events: 6000\n",
      "--- mydataset                : [AE Transform] Number of classes: 2\n",
      "--- mydataset                : [AE Transform] Initial number of variables: 6\n",
      "--- mydataset                : [AE Transform] Adding transformed variable ae_transformed_var0 to new DataLoader\n",
      "--- mydataset                : [AE Transform] Adding transformed variable ae_transformed_var1 to new DataLoader\n",
      "--- mydataset                : [AE Transform] Adding transformed variable ae_transformed_var2 to new DataLoader\n",
      "--- mydataset                : [AE Transform] New data with transformed variables has been written to mydataset_ae_transformed.root file\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Signal\"\t with internal class number 0\n",
      "--- mydataset                : Add Tree Signal of type Signal with 3000 events\n",
      "--- DataSetInfo              : Dataset[mydataset] : Added class \"Background\"\t with internal class number 1\n",
      "--- mydataset                : Add Tree Background of type Background with 3000 events\n",
      "--- DataSetInfo              : Dataset[mydataset] : Class index : 0  name : Signal\n",
      "--- DataSetInfo              : Dataset[mydataset] : Class index : 1  name : Background\n",
      "--- mydataset                : [AE Transform] Number of variables after transformation: 3\n"
     ]
    }
   ],
   "source": [
    "newloader = loader.VarTransform(\"AE(indexLayer=1;pretraining=false;!H:V:ErrorStrategy=SUMOFSQUARES:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|3,LINEAR:TrainingStrategy=LearningRate=1e-1,Momentum=0.0,Repetitions=1,ConvergenceSteps=300,BatchSize=20,TestRepetitions=15,WeightDecay=0.001,Regularization=NONE,DropConfig=0.0+0.5+0.5+0.5,DropRepetitions=1,Multithreading=True|LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=300,BatchSize=30,TestRepetitions=7,WeightDecay=0.001,Regularization=L2,Multithreading=True,DropConfig=0.0+0.1+0.1+0.1,DropRepetitions=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"jstmva_1\" style=\"width: 800px; height:450px\"></div>\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'JsMVA':'https://rawgit.com/qati/GSOC16/master/src/js/JsMVA.min'\n",
       "        }\n",
       "    });\n",
       "    require(['JsMVA'],function(jsmva){\n",
       "        jsmva.drawNeuralNetwork('jstmva_1','{\"layers\": [{\"Connection\": \"FULL\", \"OutputMode\": \"1\", \"Nodes\": \"3\", \"ActivationFunction\": \"T\"}, {\"Connection\": \"FULL\", \"OutputMode\": \"1\", \"Nodes\": \"6\", \"ActivationFunction\": \"L\"}], \"variables\": [\"var0\", \"var1\", \"var2\", \"var0-var1\", \"var0*var2\", \"var1+var2\"], \"synapses\": {\"NumberSynapses\": \"39\", \"synapses\": [\"2.4256838170070988e-01\", \"-1.2383367563160655e-01\", \"-1.9029246228212623e-01\", \"-3.3679536380298064e-01\", \"-9.4998367107983345e-02\", \"7.6465675253596085e-02\", \"2.0348972537343554e-01\", \"-1.3813697893067461e-01\", \"1.4180045707076731e-02\", \"5.1125523263013328e-01\", \"-5.1602918857857383e-01\", \"-1.2343984816831576e-01\", \"2.6352127480199070e+00\", \"1.4167086622498670e-01\", \"-1.3573376201572742e+00\", \"-1.1525676738448370e-01\", \"-6.5045821810859694e-01\", \"8.9955793357542779e-02\", \"-4.4930160984460343e+00\", \"8.7807217198135401e+00\", \"1.7231473556590710e-01\", \"1.5771780146834384e+00\", \"-8.8535459688797369e-01\", \"-8.6829423732745895e-02\", \"2.4625323779104420e+00\", \"6.8776206782897900e+00\", \"-9.7218316544020433e-01\", \"3.9231825388327675e+00\", \"5.1185248664278493e-01\", \"2.8087099416339938e+00\", \"3.4113298352026908e+00\", \"1.5105664468647555e+01\", \"3.3205632269383849e+00\", \"-8.6870803281088771e-01\", \"-3.3075270852990518e-01\", \"-6.8357512946402088e-01\", \"-5.3795538314516966e-01\", \"-5.1432053440794947e+00\", \"-1.0143276269726229e+00\"], \"OutputSize\": \"6\", \"InputSize\": \"7\"}}');\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factory.DrawNeuralNetwork(\"ae_transform_dataset\", \"DNN\", True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
